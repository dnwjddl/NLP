{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'a', 'computational', 'process.', 'Computational', 'processes', 'are', 'abstract', 'beings', 'that', 'inhabit', 'computers.', 'As', 'they', 'evolve,', 'processes', 'manipulate', 'other', 'abstract', 'things', 'called', 'data.', 'The', 'evolution', 'of', 'a', 'process', 'is', 'directed', 'by', 'a', 'pattern', 'of', 'rules', 'called', 'a', 'program.', 'People', 'create', 'programs', 'to', 'direct', 'processes.', 'In', 'effect,', 'we', 'conjure', 'the', 'spirits', 'of', 'the', 'computer', 'with', 'our', 'spells.']\n",
      "{'idea', 'effect,', 'spirits', 'In', 'are', 'manipulate', 'The', 'As', 'data.', 'Computational', 'with', 'People', 'about', 'direct', 'computer', 'the', 'process', 'abstract', 'a', 'our', 'We', 'they', 'directed', 'programs', 'that', 'study', 'to', 'process.', 'inhabit', 'program.', 'processes.', 'things', 'beings', 'of', 'computational', 'evolution', 'processes', 'is', 'rules', 'spells.', 'by', 'we', 'computers.', 'other', 'called', 'evolve,', 'pattern', 'conjure', 'create'}\n",
      "vocab_size: 49\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2 #Window size을 뜻함\n",
    "\n",
    "text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "#띄어쓰기 기준으로 split\n",
    "\n",
    "print(text)\n",
    "vocab = set(text) #text는 배열안에 존재 vocab 나눠준거 {'We','are',.. } 이런식으로 \n",
    "#set 함수는 dictionary 와 비슷하지만, key가 없고 값만 존재한다.\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)\n",
    "print('vocab_size:', vocab_size)\n",
    "\n",
    "#단어 사전 만듦 key, value 바꿔가면서\n",
    "w2i = {w: i for i, w in enumerate(vocab)}\n",
    "i2w = {i: w for i, w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token생성했으므로 -> (Make Corpus: Numbering(Dictionary))\n",
    "## => 단어 임베딩 필요 <word2Vec 사용>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 임베딩을 위한 trainset 전처리 과정\n",
    "- Negative Sampling 이란 Softmax 함수를 전체 trainset에 말고 window 밖의 일부 trainset에만 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow sample (['We', 'are', 'to', 'study'], 'about')\n",
      "skipgram sample ('about', 'We', 1)\n",
      "skipgram sample ('about', 'We', 0)\n"
     ]
    }
   ],
   "source": [
    "##train을 위한 데이터셋을 만들어줌\n",
    "\n",
    "##Word2Vec중 CBOW 쓸때\n",
    "def create_cbow_dataset(text):\n",
    "    data = []\n",
    "    for i in range(2, len(text) - 2): #context size을 설정해준대로 2빼기\n",
    "        context = [text[i - 2], text[i - 1],\n",
    "                   text[i + 1], text[i + 2]] #context word 중심단어 옆에 주변단어들 list\n",
    "        target = text[i] #중심단어임\n",
    "        data.append((context, target)) #data라는 list 에 (주변단어, 중심단어) 로 설정\n",
    "    return data\n",
    "\n",
    "##Word2Vec중 skipgram 쓸때 + Negative Sampling을 위한 data set도 만들어주기\n",
    "def create_skipgram_dataset(text):\n",
    "    import random\n",
    "    data = [] \n",
    "    for i in range(2, len(text) - 2):\n",
    "        data.append((text[i], text[i-2], 1))\n",
    "        data.append((text[i], text[i-1], 1))\n",
    "        data.append((text[i], text[i+1], 1))\n",
    "        data.append((text[i], text[i+2], 1))\n",
    "        #data라는 list에 (중심단어, 주변단어) 설정\n",
    "        ##negative Sampling 하는 방법// random으로 id 부여\n",
    "        #random id에 대한 텍스트는 관계가 없다라는 값을 넣어줌\n",
    "        for _ in range(4):\n",
    "            if random.random() < 0.5 or i >= len(text) - 3:\n",
    "                rand_id = random.randint(0, i-1)\n",
    "            else:\n",
    "                rand_id = random.randint(i+3, len(text)-1)\n",
    "            data.append((text[i], text[rand_id], 0)) \n",
    "            #random으로 뽑힌 아이디 값도 (중심단어, negative 주변단어) 설정.\n",
    "            #대신 weight는 관계가 없으니, 0으로 넣어줌. weight 업데이트 해줄 필요성 없음 (해주기엔 너무 많은 양의 계산이 필요함)\n",
    "    return data\n",
    "\n",
    "cbow_train = create_cbow_dataset(text)\n",
    "skipgram_train = create_skipgram_dataset(text)\n",
    "print('cbow sample', cbow_train[0]) \n",
    "print('skipgram sample', skipgram_train[0]) \n",
    "print('skipgram sample', skipgram_train[4]) #random으로 negative Sampling 한거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW&SKIPGRAM 단일 신경망 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##학습 전 학습을 위한 단일 신경망 제작.\n",
    "#CBOW 형태의 단일 신경망 제작\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_size, context_size, hidden_size):\n",
    "        super(CBOW, self).__init__() #super 상속 개념 : 자식 클래스에서 부모 클래스를 사용하고 싶을 경우 \n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embd_size) #임베딩 벡터를 얻기 위한 임베딩layer\n",
    "        #nn.Embeddding(num_embeddings=len(vocab),embedding_dim=3,pedding_idx=1) #dim 벡터의 차원(사용자가 지정해줌)\n",
    "        #차원을 맞춰주기 위함 (embd_size로)\n",
    "        \n",
    "        #nn.Linear(input_dim, output_dim)        \n",
    "        self.linear1 = nn.Linear(2*context_size*embd_size, hidden_size) #inputlayer\n",
    "        #context_size=window size, 한단어 마다 embd_size만큼, * data set 은 (context, target)으로 구성 즉, *2 해주기\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size) \n",
    "        #Output layer. CBOW는 vocab_size 만큼 나와야함.\n",
    "        #size를 맞춰주기 위해서 vocab_size로 output를 둠\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        ##embedded(벡터화)->layer1->Relu->hid->layer2->softmax()->log_probs\n",
    "        embedded = self.embeddings(inputs).view((1, -1)) \n",
    "        hid = F.relu(self.linear1(embedded))\n",
    "        #embedded를 넣고 relu를 돌린후 hid에 넣기\n",
    "        out = self.linear2(hid) \n",
    "        #레이어2를 hid를 넣어서 out 나오게\n",
    "        log_probs = F.log_softmax(out) #softmax 사용\n",
    "        return log_probs #CBOW output 값\n",
    "    \n",
    "    \n",
    "#SkipGram 형태의 단일 신경망 제작\n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_size):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embd_size) \n",
    "        #embedding벡터만 필요\n",
    "        #둘의 곱으로 표현된 embedding matrix\n",
    "    \n",
    "    def forward(self, focus, context):\n",
    "        embed_focus = self.embeddings(focus).view((1, -1))  \n",
    "        # .view:1차원으로 만들어줌 차원 reshape 해주기(1,-1) #단, -1 을 다른 차원에 맞춰서 자동으로 차원 설정\n",
    "        \n",
    "        embed_ctx = self.embeddings(context).view((1, -1)) #focus 와 context 로 쭉쭉 펴줌\n",
    "        score = torch.mm(embed_focus, torch.t(embed_ctx)) #torch.mm : 내적을한다는 뜻\n",
    "        \n",
    "        #행렬곱을 진행. 높을수록 관련있다\n",
    "        log_probs = F.logsigmoid(score) #시그모이드 진행\n",
    "    \n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW 와 SKIPGRAM 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram(\n",
      "  (embeddings): Embedding(49, 100)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SkipGram(\n",
       "   (embeddings): Embedding(49, 100)\n",
       " ),\n",
       " [tensor(16796.6875),\n",
       "  tensor(3396.6379),\n",
       "  tensor(1258.6238),\n",
       "  tensor(686.8545),\n",
       "  tensor(481.5197),\n",
       "  tensor(393.8079),\n",
       "  tensor(349.8574),\n",
       "  tensor(324.4760),\n",
       "  tensor(308.1470),\n",
       "  tensor(296.7898),\n",
       "  tensor(288.4325),\n",
       "  tensor(282.0202),\n",
       "  tensor(276.9409),\n",
       "  tensor(272.8154),\n",
       "  tensor(269.3961),\n",
       "  tensor(266.5149),\n",
       "  tensor(264.0533),\n",
       "  tensor(261.9250),\n",
       "  tensor(260.0661),\n",
       "  tensor(258.4284),\n",
       "  tensor(256.9742),\n",
       "  tensor(255.6741),\n",
       "  tensor(254.5048),\n",
       "  tensor(253.4474),\n",
       "  tensor(252.4862),\n",
       "  tensor(251.6086),\n",
       "  tensor(250.8044),\n",
       "  tensor(250.0644),\n",
       "  tensor(249.3813),\n",
       "  tensor(248.7488)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embd_size = 100 #각 단어 별로 100차원으로 설정\n",
    "learning_rate = 0.001 \n",
    "n_epoch = 30 #전체 데이터를 몇번 훑을지\n",
    "\n",
    "\n",
    "# CBOW(\n",
    "#   (embeddings): Embedding(49, 100)\n",
    "#   (linear1): Linear(in_features=400, out_features=64, bias=True)\n",
    "#   (linear2): Linear(in_features=64, out_features=49, bias=True)\n",
    "# )\n",
    "\n",
    "\n",
    "def train_cbow():\n",
    "    hidden_size = 64 \n",
    "    losses = [] #loss값을 계산하고 그 값을 list에 입력\n",
    "    loss_fn = nn.NLLLoss() #loss function\n",
    "    model = CBOW(vocab_size, embd_size, CONTEXT_SIZE, hidden_size) #CBOW 클래스\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate) #pytorch 에서 weight 갱신해주는 패키지\n",
    "    # optim 패키지를 사용하여 모델의 가중치를 갱신할 Optimizer를 정의합니다.\n",
    "    # optim 패키지도 종류가 많다. 이중 우린 SGD (GradientDescent) 사용. (그외, RMS, Adam등)\n",
    "\n",
    "\n",
    "    for epoch in range(n_epoch): #epoch 만큼\n",
    "        total_loss = .0 #전체적인 loss 값은 0\n",
    "        \n",
    "        for context, target in cbow_train: #context, target 돌아가기\n",
    "            ctx_idxs = [w2i[w] for w in context] #context만으로 index 설정\n",
    "            ctx_var = Variable(torch.LongTensor(ctx_idxs)) #Variable 로 index들을 벡터화 시켜줌 \n",
    "            #torch.LongTensor -> 데이터 타입임 자료형변환\n",
    "            \n",
    "            model.zero_grad() #model의 weight을 0으로 초기화\n",
    "            log_probs = model(ctx_var)#벡터화시킨걸 model에 돌리기 \n",
    "            #예상값이 나옴\n",
    "            \n",
    "            loss = loss_fn(log_probs, Variable(torch.LongTensor([w2i[target]])))\n",
    "            #타겟값과 probality 계산\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step() #weight 업데이트\n",
    "            total_loss += loss.data #loss 리스트에 업데이트\n",
    "        losses.append(total_loss)\n",
    "    return model, losses\n",
    "\n",
    "def train_skipgram():\n",
    "    losses = [] \n",
    "    loss_fn = nn.MSELoss() #loss 는 MSE로 넣어봄 \n",
    "    model = SkipGram(vocab_size, embd_size) #CBOW 와 다르게 두개만 받게 설정\n",
    "    print(model)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate) #SGD로 OPtimizer 설정\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = .0\n",
    "        for in_w, out_w, target in skipgram_train:\n",
    "            in_w_var = Variable(torch.LongTensor([w2i[in_w]]))\n",
    "            out_w_var = Variable(torch.LongTensor([w2i[out_w]])) \n",
    "            \n",
    "            model.zero_grad()\n",
    "            log_probs = model(in_w_var, out_w_var)\n",
    "            loss = loss_fn(log_probs[0], Variable(torch.Tensor([target])))\n",
    "            #loss계산\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #loss계산한거 backpropagation 하고 optimizer를 통해 weight 갱신\n",
    "            \n",
    "            total_loss += loss.data\n",
    "        losses.append(total_loss)\n",
    "    return model, losses\n",
    "\n",
    "train_skipgram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram(\n",
      "  (embeddings): Embedding(49, 100)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cbow_model, cbow_losses = train_cbow()\n",
    "sg_model, sg_losses = train_skipgram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testset model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cbow(test_data, model):\n",
    "    print('====Test CBOW===')\n",
    "    correct_ct = 0\n",
    "    for ctx, target in test_data:\n",
    "        ctx_idxs = [w2i[w] for w in ctx] #index 값을 뽑아냄\n",
    "        ctx_var = Variable(torch.LongTensor(ctx_idxs)) #variable 뽑아냄\n",
    "\n",
    "        model.zero_grad()\n",
    "        log_probs = model(ctx_var)\n",
    "        \n",
    "        ##MAX 맞추기 위함\n",
    "        _, predicted = torch.max(log_probs.data, 1) #log_prob에서 max로 뽑아냄\n",
    "        ##제일 높은 값의 item 맞추기\n",
    "        predicted_word = i2w[predicted.item()]  #제일 높은 값을 item으로\n",
    "        print('predicted:', predicted_word)\n",
    "        print('label    :', target)\n",
    "        if predicted_word == target: # taget이랑 predict 한거랑 같았으면 값은 1, 다르면 0\n",
    "            correct_ct += 1 \n",
    "    #0과 1의 값으로 Accuracy 계산       \n",
    "    print('Accuracy: {:.1f}% ({:d}/{:d})'.format(correct_ct/len(test_data)*100, correct_ct, len(test_data)))\n",
    "\n",
    "def test_skipgram(test_data, model):\n",
    "    print('====Test SkipGram===')\n",
    "    correct_ct = 0\n",
    "    for in_w, out_w, target in test_data:#두 in out 관련 있으면 1, 없으면 0\n",
    "        in_w_var = Variable(torch.LongTensor([w2i[in_w]]))\n",
    "        out_w_var = Variable(torch.LongTensor([w2i[out_w]]))\n",
    "\n",
    "        model.zero_grad() \n",
    "        \n",
    "        log_probs = model(in_w_var, out_w_var)\n",
    "        \n",
    "        _, predicted = torch.max(log_probs.data, 1) #가장 높은 값 predicted\n",
    "        predicted = predicted[0]\n",
    "        if predicted == target: #taget이랑 맞다면 1 틀리면 0\n",
    "            correct_ct += 1\n",
    "\n",
    "    print('Accuracy: {:.1f}% ({:d}/{:d})'.format(correct_ct/len(test_data)*100, correct_ct, len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Test CBOW===\n",
      "predicted: about\n",
      "label    : about\n",
      "predicted: to\n",
      "label    : to\n",
      "predicted: study\n",
      "label    : study\n",
      "predicted: the\n",
      "label    : the\n",
      "predicted: idea\n",
      "label    : idea\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: a\n",
      "label    : a\n",
      "predicted: computational\n",
      "label    : computational\n",
      "predicted: process.\n",
      "label    : process.\n",
      "predicted: Computational\n",
      "label    : Computational\n",
      "predicted: processes\n",
      "label    : processes\n",
      "predicted: are\n",
      "label    : are\n",
      "predicted: abstract\n",
      "label    : abstract\n",
      "predicted: beings\n",
      "label    : beings\n",
      "predicted: that\n",
      "label    : that\n",
      "predicted: inhabit\n",
      "label    : inhabit\n",
      "predicted: computers.\n",
      "label    : computers.\n",
      "predicted: As\n",
      "label    : As\n",
      "predicted: they\n",
      "label    : they\n",
      "predicted: evolve,\n",
      "label    : evolve,\n",
      "predicted: processes\n",
      "label    : processes\n",
      "predicted: manipulate\n",
      "label    : manipulate\n",
      "predicted: other\n",
      "label    : other\n",
      "predicted: abstract\n",
      "label    : abstract\n",
      "predicted: things\n",
      "label    : things\n",
      "predicted: called\n",
      "label    : called\n",
      "predicted: a\n",
      "label    : data.\n",
      "predicted: The\n",
      "label    : The\n",
      "predicted: evolution\n",
      "label    : evolution\n",
      "predicted: of\n",
      "label    : "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\n",
      "predicted: a\n",
      "label    : a\n",
      "predicted: process\n",
      "label    : process\n",
      "predicted: is\n",
      "label    : is\n",
      "predicted: directed\n",
      "label    : directed\n",
      "predicted: by\n",
      "label    : by\n",
      "predicted: a\n",
      "label    : a\n",
      "predicted: pattern\n",
      "label    : pattern\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: a\n",
      "label    : rules\n",
      "predicted: called\n",
      "label    : called\n",
      "predicted: a\n",
      "label    : a\n",
      "predicted: program.\n",
      "label    : program.\n",
      "predicted: People\n",
      "label    : People\n",
      "predicted: create\n",
      "label    : create\n",
      "predicted: programs\n",
      "label    : programs\n",
      "predicted: to\n",
      "label    : to\n",
      "predicted: direct\n",
      "label    : direct\n",
      "predicted: the\n",
      "label    : processes.\n",
      "predicted: a\n",
      "label    : In\n",
      "predicted: effect,\n",
      "label    : effect,\n",
      "predicted: we\n",
      "label    : we\n",
      "predicted: conjure\n",
      "label    : conjure\n",
      "predicted: the\n",
      "label    : the\n",
      "predicted: spirits\n",
      "label    : spirits\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: the\n",
      "label    : the\n",
      "predicted: computer\n",
      "label    : computer\n",
      "predicted: with\n",
      "label    : with\n",
      "Accuracy: 93.1% (54/58)\n",
      "------\n",
      "====Test SkipGram===\n",
      "Accuracy: 50.0% (232/464)\n"
     ]
    }
   ],
   "source": [
    "test_cbow(cbow_train, cbow_model)\n",
    "print('------')\n",
    "test_skipgram(skipgram_train, sg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points, title):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(points)\n",
    "\n",
    "showPlot(cbow_losses, 'CBOW Losses')\n",
    "showPlot(sg_losses, 'SkipGram Losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchtext을 사용해서 GloVe 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 words\n"
     ]
    }
   ],
   "source": [
    "#거대한 corpus을 통해서 학습을 완료시킨 vector들\n",
    "import torch\n",
    "import torchtext.vocab as vocab #GloVe 외 많음\n",
    "\n",
    "glove = vocab.GloVe(name = \"6B\", dim = 100)\n",
    "print(\"Loaded {} words\".format(len(glove.itos))) #itos (index to string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(word):\n",
    "    return glove.vectors[glove.stoi[word]]\n",
    "#get_word(\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(vec, n = 10):\n",
    "    all_dists = [(w, torch.dist(vec, get_word(w))) for w in glove.itos]\n",
    "    return sorted(all_dists, key = lambda t: t[1])[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tuples(tuples):\n",
    "    for tuple in tuples:\n",
    "        print(\"(%.4f) %s\" % (tuple[1], tuple[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0000) google\n",
      "(3.0772) yahoo\n",
      "(3.8836) microsoft\n",
      "(4.1048) web\n",
      "(4.1082) aol\n",
      "(4.1165) facebook\n",
      "(4.3917) ebay\n",
      "(4.4122) msn\n",
      "(4.4540) internet\n",
      "(4.4651) netscape\n"
     ]
    }
   ],
   "source": [
    "print_tuples(closest(get_word(\"google\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(w1, w2, w3, n=5, filter_given=True):\n",
    "    print('\\n[%s : %s :: %s : ?]' % (w1, w2, w3))\n",
    "    closest_words = closest(get_word(w2) - get_word(w1) + get_word(w3))    \n",
    "    if filter_given:\n",
    "        closest_words = [t for t in closest_words if t[0] not in [w1, w2, w3]]\n",
    "        \n",
    "    print_tuples(closest_words[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[king : man :: queen : ?]\n",
      "(4.0811) woman\n",
      "(4.6916) girl\n",
      "(5.2703) she\n",
      "(5.2788) teenager\n",
      "(5.3084) boy\n"
     ]
    }
   ],
   "source": [
    "analogy(\"king\", \"man\", \"queen\")\n",
    "#GloVe를 통해 가장 가까운 거리의 제일 나올 수 있는 확률이 높은 다섯개의 단어 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[man : actor :: woman : ?]\n",
      "(2.8133) actress\n",
      "(5.0039) comedian\n",
      "(5.1399) actresses\n",
      "(5.2773) starred\n",
      "(5.3085) screenwriter\n",
      "\n",
      "[cat : kitten :: dog : ?]\n",
      "(3.8146) puppy\n",
      "(4.2944) rottweiler\n",
      "(4.5888) puppies\n",
      "(4.6086) pooch\n",
      "(4.6520) pug\n",
      "\n",
      "[dog : puppy :: cat : ?]\n",
      "(3.8146) kitten\n",
      "(4.0255) puppies\n",
      "(4.1575) kittens\n",
      "(4.1882) pterodactyl\n",
      "(4.1945) scaredy\n",
      "\n",
      "[russia : moscow :: france : ?]\n",
      "(3.2697) paris\n",
      "(4.6857) french\n",
      "(4.7085) lyon\n",
      "(4.9087) strasbourg\n",
      "(5.0362) marseille\n",
      "\n",
      "[obama : president :: trump : ?]\n",
      "(6.4302) executive\n",
      "(6.5149) founder\n",
      "(6.6997) ceo\n",
      "(6.7524) hilton\n",
      "(6.7729) walt\n",
      "\n",
      "[rich : mansion :: poor : ?]\n",
      "(5.8262) residence\n",
      "(5.9444) riverside\n",
      "(6.0283) hillside\n",
      "(6.0328) abandoned\n",
      "(6.0681) bungalow\n",
      "\n",
      "[elvis : rock :: eminem : ?]\n",
      "(5.6597) rap\n",
      "(6.2057) rappers\n",
      "(6.2161) rapper\n",
      "(6.2444) punk\n",
      "(6.2690) hop\n",
      "\n",
      "[paper : newspaper :: screen : ?]\n",
      "(4.7810) tv\n",
      "(5.1049) television\n",
      "(5.3818) cinema\n",
      "(5.5524) feature\n",
      "(5.5646) shows\n",
      "\n",
      "[monet : paint :: michelangelo : ?]\n",
      "(6.0782) plaster\n",
      "(6.3768) mold\n",
      "(6.3922) tile\n",
      "(6.5819) marble\n",
      "(6.6524) image\n",
      "\n",
      "[beer : barley :: wine : ?]\n",
      "(5.6021) grape\n",
      "(5.6760) beans\n",
      "(5.8174) grapes\n",
      "(5.9035) lentils\n",
      "(5.9454) figs\n",
      "\n",
      "[earth : moon :: sun : ?]\n",
      "(6.2294) lee\n",
      "(6.4125) kang\n",
      "(6.4644) tan\n",
      "(6.4757) yang\n",
      "(6.4853) lin\n",
      "\n",
      "[house : roof :: castle : ?]\n",
      "(6.2919) stonework\n",
      "(6.3779) masonry\n",
      "(6.4773) canopy\n",
      "(6.4954) fortress\n",
      "(6.5259) battlements\n",
      "\n",
      "[building : architect :: software : ?]\n",
      "(5.8369) programmer\n",
      "(6.8881) entrepreneur\n",
      "(6.9240) inventor\n",
      "(6.9730) developer\n",
      "(6.9949) innovator\n",
      "\n",
      "[boston : bruins :: phoenix : ?]\n",
      "(3.8546) suns\n",
      "(4.1968) mavericks\n",
      "(4.6126) coyotes\n",
      "(4.6894) mavs\n",
      "(4.6971) knicks\n",
      "\n",
      "[good : heaven :: bad : ?]\n",
      "(4.3959) hell\n",
      "(5.2864) ghosts\n",
      "(5.2898) hades\n",
      "(5.3414) madness\n",
      "(5.3520) purgatory\n",
      "\n",
      "[jordan : basketball :: woods : ?]\n",
      "(5.8607) golf\n",
      "(6.4110) golfers\n",
      "(6.4418) tournament\n",
      "(6.4592) tennis\n",
      "(6.6560) collegiate\n"
     ]
    }
   ],
   "source": [
    "analogy('man', 'actor', 'woman')\n",
    "analogy('cat', 'kitten', 'dog')\n",
    "analogy('dog', 'puppy', 'cat')\n",
    "analogy('russia', 'moscow', 'france')\n",
    "analogy('obama', 'president', 'trump')\n",
    "analogy('rich', 'mansion', 'poor')\n",
    "analogy('elvis', 'rock', 'eminem')\n",
    "analogy('paper', 'newspaper', 'screen')\n",
    "analogy('monet', 'paint', 'michelangelo')\n",
    "analogy('beer', 'barley', 'wine')\n",
    "analogy('earth', 'moon', 'sun')\n",
    "analogy('house', 'roof', 'castle')\n",
    "analogy('building', 'architect', 'software')\n",
    "analogy('boston', 'bruins', 'phoenix')\n",
    "analogy('good', 'heaven', 'bad')\n",
    "analogy('jordan', 'basketball', 'woods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
